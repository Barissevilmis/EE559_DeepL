{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import AUXN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU (CUDA) is available!\n",
      "Epoch 0 , Current learning rate: [0.005] , Epoch loss: 17.418031692504883\n",
      "Epoch 1 , Current learning rate: [0.005] , Epoch loss: 15.097920179367065\n",
      "Epoch 2 , Current learning rate: [0.005] , Epoch loss: 14.598367094993591\n",
      "Epoch 3 , Current learning rate: [0.005] , Epoch loss: 14.350972890853882\n",
      "Epoch 4 , Current learning rate: [0.005] , Epoch loss: 13.932351231575012\n",
      "Epoch 5 , Current learning rate: [0.005] , Epoch loss: 13.604546427726746\n",
      "Epoch 6 , Current learning rate: [0.005] , Epoch loss: 13.5091792345047\n",
      "Epoch 7 , Current learning rate: [0.005] , Epoch loss: 13.48755657672882\n",
      "Epoch 8 , Current learning rate: [0.005] , Epoch loss: 13.46717095375061\n",
      "Epoch 9 , Current learning rate: [0.005] , Epoch loss: 13.458851099014282\n",
      "Epoch 10 , Current learning rate: [0.005] , Epoch loss: 13.395645141601562\n",
      "Epoch 11 , Current learning rate: [0.005] , Epoch loss: 13.396801471710205\n",
      "Epoch 12 , Current learning rate: [0.005] , Epoch loss: 13.351804614067078\n",
      "Epoch 13 , Current learning rate: [0.005] , Epoch loss: 13.355247139930725\n",
      "Epoch 14 , Current learning rate: [0.0005] , Epoch loss: 13.345157861709595\n",
      "Epoch 15 , Current learning rate: [0.0005] , Epoch loss: 13.281193137168884\n",
      "Epoch 16 , Current learning rate: [0.0005] , Epoch loss: 13.250885009765625\n",
      "Epoch 17 , Current learning rate: [0.0005] , Epoch loss: 13.251607775688171\n",
      "Epoch 18 , Current learning rate: [0.0005] , Epoch loss: 13.27544641494751\n",
      "Epoch 19 , Current learning rate: [0.0005] , Epoch loss: 13.23202908039093\n",
      "Epoch 20 , Current learning rate: [0.0005] , Epoch loss: 13.246607899665833\n",
      "Epoch 21 , Current learning rate: [0.0005] , Epoch loss: 13.235768556594849\n",
      "Epoch 22 , Current learning rate: [0.0005] , Epoch loss: 13.231412649154663\n",
      "Epoch 23 , Current learning rate: [0.0005] , Epoch loss: 13.235713958740234\n",
      "Epoch 24 , Current learning rate: [0.0005] , Epoch loss: 13.232141971588135\n",
      "Epoch 25 , Current learning rate: [0.0005] , Epoch loss: 13.221442222595215\n",
      "Epoch 26 , Current learning rate: [0.0005] , Epoch loss: 13.225883603096008\n",
      "Epoch 27 , Current learning rate: [0.0005] , Epoch loss: 13.228549599647522\n",
      "Epoch 28 , Current learning rate: [0.0005] , Epoch loss: 13.207401871681213\n",
      "Epoch 29 , Current learning rate: [5e-05] , Epoch loss: 13.201347708702087\n",
      "Epoch 30 , Current learning rate: [5e-05] , Epoch loss: 13.193571209907532\n",
      "Epoch 31 , Current learning rate: [5e-05] , Epoch loss: 13.211251735687256\n",
      "Epoch 32 , Current learning rate: [5e-05] , Epoch loss: 13.202070951461792\n",
      "Epoch 33 , Current learning rate: [5e-05] , Epoch loss: 13.202494859695435\n",
      "Epoch 34 , Current learning rate: [5e-05] , Epoch loss: 13.207905888557434\n",
      "Epoch 35 , Current learning rate: [5e-05] , Epoch loss: 13.204190969467163\n",
      "Epoch 36 , Current learning rate: [5e-05] , Epoch loss: 13.216964602470398\n",
      "Epoch 37 , Current learning rate: [5e-05] , Epoch loss: 13.198747634887695\n",
      "Epoch 38 , Current learning rate: [5e-05] , Epoch loss: 13.197039246559143\n",
      "Epoch 39 , Current learning rate: [5e-05] , Epoch loss: 13.195452809333801\n",
      "Epoch 40 , Current learning rate: [5e-05] , Epoch loss: 13.208281993865967\n",
      "Epoch 41 , Current learning rate: [5e-05] , Epoch loss: 13.200140833854675\n",
      "Epoch 42 , Current learning rate: [5e-05] , Epoch loss: 13.196831345558167\n",
      "Epoch 43 , Current learning rate: [5e-05] , Epoch loss: 13.20836627483368\n",
      "Epoch 44 , Current learning rate: [5e-06] , Epoch loss: 13.208926796913147\n",
      "Epoch 45 , Current learning rate: [5e-06] , Epoch loss: 13.207319259643555\n",
      "Epoch 46 , Current learning rate: [5e-06] , Epoch loss: 13.195591568946838\n",
      "Epoch 47 , Current learning rate: [5e-06] , Epoch loss: 13.20960247516632\n",
      "Epoch 48 , Current learning rate: [5e-06] , Epoch loss: 13.204486846923828\n",
      "Epoch 49 , Current learning rate: [5e-06] , Epoch loss: 13.192381024360657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([17.4180, 15.0979, 14.5984, 14.3510, 13.9324, 13.6045, 13.5092, 13.4876,\n",
       "         13.4672, 13.4589, 13.3956, 13.3968, 13.3518, 13.3552, 13.3452, 13.2812,\n",
       "         13.2509, 13.2516, 13.2754, 13.2320, 13.2466, 13.2358, 13.2314, 13.2357,\n",
       "         13.2321, 13.2214, 13.2259, 13.2285, 13.2074, 13.2013, 13.1936, 13.2113,\n",
       "         13.2021, 13.2025, 13.2079, 13.2042, 13.2170, 13.1987, 13.1970, 13.1955,\n",
       "         13.2083, 13.2001, 13.1968, 13.2084, 13.2089, 13.2073, 13.1956, 13.2096,\n",
       "         13.2045, 13.1924]),\n",
       " tensor([0.7270, 0.8460, 0.8830, 0.9050, 0.9220, 0.9400, 0.9420, 0.9360, 0.9460,\n",
       "         0.9430, 0.9590, 0.9580, 0.9610, 0.9550, 0.9590, 0.9610, 0.9630, 0.9570,\n",
       "         0.9630, 0.9640, 0.9660, 0.9670, 0.9640, 0.9700, 0.9700, 0.9660, 0.9720,\n",
       "         0.9660, 0.9660, 0.9730, 0.9720, 0.9700, 0.9640, 0.9660, 0.9690, 0.9670,\n",
       "         0.9730, 0.9660, 0.9660, 0.9730, 0.9670, 0.9670, 0.9700, 0.9730, 0.9690,\n",
       "         0.9780, 0.9730, 0.9700, 0.9700, 0.9680]),\n",
       " tensor([0.7350, 0.8300, 0.8730, 0.8750, 0.9080, 0.9280, 0.9310, 0.9040, 0.9050,\n",
       "         0.9280, 0.9230, 0.9240, 0.9280, 0.9240, 0.9270, 0.9340, 0.9280, 0.9330,\n",
       "         0.9340, 0.9440, 0.9440, 0.9340, 0.9370, 0.9350, 0.9350, 0.9420, 0.9300,\n",
       "         0.9490, 0.9360, 0.9400, 0.9420, 0.9420, 0.9410, 0.9420, 0.9430, 0.9400,\n",
       "         0.9400, 0.9420, 0.9460, 0.9430, 0.9360, 0.9480, 0.9360, 0.9400, 0.9360,\n",
       "         0.9360, 0.9430, 0.9370, 0.9370, 0.9380]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AUXN.AuxiliaryNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "(train_input, train_target, train_classes), (test_input,\n",
    "                                             test_target, test_classes) = utils.generate_dataset(1000)\n",
    "train_dataset, test_dataset = utils.preprocess_dataset(train_input, train_target, train_classes, test_input,\n",
    "                                                       test_target, test_classes)\n",
    "\n",
    "utils.train_model(model, train_dataset, test_dataset, criterion, epochs=50, **\n",
    "                  {\"lr\": 0.005, \"weight_decay\": 0.0001, \"batch_size\": 100, \"aux_param\": 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0\n",
      "Softmax result class 1: 0.9994872808456421\n",
      "Softmax result class 2: 0.0005126874893903732\n",
      "Test target: 1\n",
      "Test class 1: 4\n",
      "Test class 2: 5\n",
      "Digit 1: 7\n",
      "Digit 2: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in range(999):\n",
    "    pd, digit1, digit2 = model(test_input[sample:sample+2].to(\"cuda\")) # +2 to make it look like batch size\n",
    "    result=0 if pd[0,0].item()>pd[0,1].item() else 1\n",
    "    if result != test_target[sample].item():\n",
    "        print(\"Output:\",result)\n",
    "        print(\"Softmax result class 1:\",pd[0,0].item())\n",
    "        print(\"Softmax result class 2:\",pd[0,1].item())\n",
    "        print(\"Test target:\",test_target[sample].item())\n",
    "        print(\"Test class 1:\",test_classes[sample][0].item())\n",
    "        print(\"Test class 2:\",test_classes[sample][1].item())\n",
    "        print(\"Digit 1:\",torch.argmax(digit1).item())\n",
    "        print(\"Digit 2:\",torch.argmax(digit2).item())\n",
    "        # pick a sample to plot\n",
    "        image1, image2 = test_input[sample].split(split_size=1, dim=0)\n",
    "        # plot the sample\n",
    "        fig = plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(image1.squeeze(), cmap='gray')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(image2.squeeze(), cmap='gray')\n",
    "        plt.show()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
